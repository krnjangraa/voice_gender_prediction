{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5cf6f7-6c30-4d49-baa9-cb68faf69c9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "fa5cf6f7-6c30-4d49-baa9-cb68faf69c9a",
        "outputId": "0f913da0-03f4-4861-8e13-6296c4f19a8a"
      },
      "outputs": [],
      "source": [
        "voice = pd.read_csv('https://cainvas-static.s3.amazonaws.com/media/user_data/cainvas-admin/voice.csv')\n",
        "voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba56e39-e524-4149-90fa-1975c5b1f6de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9ba56e39-e524-4149-90fa-1975c5b1f6de",
        "outputId": "cda867d6-78d2-4a08-8de2-417002368ae1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "voice['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59de329-43d3-470b-8747-dfd01adad3b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "e59de329-43d3-470b-8747-dfd01adad3b2",
        "outputId": "85af4f3f-c5c0-4299-b832-51a06a7162ca"
      },
      "outputs": [],
      "source": [
        "#correlation between various attributes\n",
        "corr = voice.corr(numeric_only=True)\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a659eea0-5de1-47c6-9c43-22c1e9f50e9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "a659eea0-5de1-47c6-9c43-22c1e9f50e9b",
        "outputId": "05615c6d-8213-4471-bbe8-7fa943450aae"
      },
      "outputs": [],
      "source": [
        " # removing columns where corelation is more than .95\n",
        "\n",
        "final_columns = list(voice.columns)    # maintaining a temporary list to remove columns from\n",
        "\n",
        "for i in range(corr.shape[0]):\n",
        "    for j in range(i+1, corr.shape[0]):\n",
        "        if corr.iloc[i, j] >= 0.95:\n",
        "            if list(voice.columns)[j] in final_columns:\n",
        "                final_columns.remove(list(voice.columns)[j])\n",
        "\n",
        "voice = voice[final_columns]\n",
        "\n",
        "voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36f73a9-d8ab-46e2-820f-1e23272e95d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "f36f73a9-d8ab-46e2-820f-1e23272e95d6",
        "outputId": "1720327f-1342-44ac-fd5f-d6c9da020665"
      },
      "outputs": [],
      "source": [
        "voice.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9d44f6-4a40-426f-a83f-6f87ac6f8916",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b9d44f6-4a40-426f-a83f-6f87ac6f8916",
        "outputId": "09bccd7c-028b-41f8-c75b-facdcb160788"
      },
      "outputs": [],
      "source": [
        "input_columns = list(voice.columns[:-1])\n",
        "output_columns = ['male', 'female']    # column names to be used after one-hot encoding\n",
        "print(\"Number of input columns: \", len(input_columns))\n",
        "print(\"Number of output columns: \", len(output_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b310d0bc-4188-4b09-b03c-b2b8a05b6d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b310d0bc-4188-4b09-b03c-b2b8a05b6d24",
        "outputId": "46d4c3ce-7d5b-4feb-dacc-e5c3df0e43d8"
      },
      "outputs": [],
      "source": [
        "# One hot encoding the labels\n",
        "y = pd.get_dummies(voice.label)\n",
        "print(y)\n",
        "\n",
        "for x in output_columns:\n",
        "    voice[x] = y[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98d6f82-81b0-4ef8-9bee-07968402c7f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "b98d6f82-81b0-4ef8-9bee-07968402c7f3",
        "outputId": "12887eec-701c-4a70-ba58-2d591d1ef7d0"
      },
      "outputs": [],
      "source": [
        "voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cdb4362-e5c2-45dc-b409-d6da32e15785",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cdb4362-e5c2-45dc-b409-d6da32e15785",
        "outputId": "4461579a-375a-48f4-ddcd-363d3f1b4d81"
      },
      "outputs": [],
      "source": [
        "# Splitting into train, val and test set -- 80-10-10 split\n",
        "\n",
        "# 80-20 split\n",
        "train_df, val_test_df = train_test_split(voice, test_size = 0.2)\n",
        "\n",
        "# Then split the 20% into half\n",
        "val_df, test_df = train_test_split(val_test_df, test_size = 0.5)\n",
        "\n",
        "print(\"Number of samples in...\")\n",
        "print(\"Training set: \", len(train_df))\n",
        "print(\"Validation set: \", len(val_df))\n",
        "print(\"Testing set: \", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99303c5-df27-45c7-a0d5-a27abc3b34f5",
      "metadata": {
        "id": "d99303c5-df27-45c7-a0d5-a27abc3b34f5"
      },
      "outputs": [],
      "source": [
        "# Splitting into X (input) and y (output)\n",
        "\n",
        "Xtrain, ytrain = np.array(train_df[input_columns]), np.array(train_df[output_columns])\n",
        "\n",
        "Xval, yval = np.array(val_df[input_columns]), np.array(val_df[output_columns])\n",
        "\n",
        "Xtest, ytest = np.array(test_df[input_columns]), np.array(test_df[output_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29d8862-948c-4ad7-b627-6410914ea33e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "c29d8862-948c-4ad7-b627-6410914ea33e",
        "outputId": "8a40f157-1eb9-474a-bbc2-afe37b12ac40"
      },
      "outputs": [],
      "source": [
        "# Each feature has a different range.\n",
        "# Using min_max_scaler to scale them to values in the range [0,1].\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Fit on training set alone\n",
        "Xtrain = min_max_scaler.fit_transform(Xtrain)\n",
        "\n",
        "# Use it to transform val and test input\n",
        "Xval = min_max_scaler.transform(Xval)\n",
        "Xtest = min_max_scaler.transform(Xtest)\n",
        "\n",
        "voice.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5b7a82-4845-4018-94ba-c20edb7a725b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "3c5b7a82-4845-4018-94ba-c20edb7a725b",
        "outputId": "3757a0a8-93ba-4c02-b95a-0469162586a3"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(16, activation = 'relu', input_shape = Xtrain[0].shape),\n",
        "    layers.Dense(8, activation = 'relu'),\n",
        "    layers.Dense(len(output_columns), activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(0.01), loss = tf.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience = 5),    # stop if the val_loss metric doesn;t increase for 5 epochs continuously.\n",
        "             ModelCheckpoint('gender_recognition_voice.keras', save_best_only=True)]   # save the best model yet\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c93563-3de8-4262-831f-ffba56f9ed1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8c93563-3de8-4262-831f-ffba56f9ed1d",
        "outputId": "1d6900e3-c55f-41e7-bf15-9b75272df46f"
      },
      "outputs": [],
      "source": [
        "history = model.fit(Xtrain, ytrain, validation_data = (Xval, yval), epochs=32, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5229c153-e648-42e4-bd65-421716d15627",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5229c153-e648-42e4-bd65-421716d15627",
        "outputId": "47b802b5-e5dc-4fee-86b4-327a2d9fd637"
      },
      "outputs": [],
      "source": [
        "model.load_weights('gender_recognition_voice.keras')    # Load the weights of the best model\n",
        "\n",
        "model.evaluate(Xtest, ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eEyAYUHUbUWZ",
      "metadata": {
        "id": "eEyAYUHUbUWZ"
      },
      "outputs": [],
      "source": [
        "def plot(history, variable, variable1):\n",
        "    plt.plot(range(len(history[variable])), history[variable])\n",
        "    plt.plot(range(len(history[variable1])), history[variable1])\n",
        "    plt.title(variable)\n",
        "    plt.legend([variable, variable1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SKHRWwbrbap0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "SKHRWwbrbap0",
        "outputId": "6f604b7c-a8bb-4fd5-93d2-bcaa460cd4dc"
      },
      "outputs": [],
      "source": [
        "plot(history.history, \"accuracy\", \"val_accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0UIH5wKlbdEv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "0UIH5wKlbdEv",
        "outputId": "a59e537b-3ff1-4eb2-880d-944df48ae56f"
      },
      "outputs": [],
      "source": [
        "plot(history.history, \"loss\", \"val_loss\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05YmV-61bgz_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05YmV-61bgz_",
        "outputId": "70df7ff0-50a4-4544-e98e-08faf666bae8"
      },
      "outputs": [],
      "source": [
        "# Pick random test sample\n",
        "i = random.randint(0, len(test_df)-1)\n",
        "\n",
        "model_output = model.predict(Xtest[i].reshape(1, -1))[0]\n",
        "pred = np.argmax(model_output)\n",
        "\n",
        "# show predicted output\n",
        "print (\"\\nModel predicted the gender: \", output_columns[pred])\n",
        "\n",
        "# actual output\n",
        "print(\"Actual gender: \", output_columns[np.argmax(ytest[i])], \"with probability\", model_output[pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SkkOBrTkbjtU",
      "metadata": {
        "id": "SkkOBrTkbjtU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75c2a66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a75c2a66",
        "outputId": "3270de8e-0d43-4c51-fc92-95058947229f"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pydub\n",
        "import soundfile as sf\n",
        "from scipy.stats import skew, kurtosis\n",
        "print(\"Imported librosa, pydub, soundfile, and scipy.stats.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2b3408",
      "metadata": {
        "id": "1c2b3408"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import scipy.stats\n",
        "import soundfile as sf # For loading diverse audio formats\n",
        "import os\n",
        "\n",
        "def extract_features_and_scale(file_path, scaler, input_columns, sr=22050):\n",
        "    \"\"\"\n",
        "    Extracts 17 audio features from an audio file and scales them using a pre-fitted MinMaxScaler.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the audio file.\n",
        "        scaler (MinMaxScaler): A pre-fitted MinMaxScaler object.\n",
        "        input_columns (list): List of 17 feature names in the expected order.\n",
        "        sr (int): Target sample rate for audio processing.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A (1, 17) array of scaled features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Load Audio, limit duration to 5s for faster processing\n",
        "        y, sr = librosa.load(file_path, sr=sr, mono=True, duration=5.0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading audio file {file_path}: {e}\")\n",
        "        # Return a zero array of features if audio cannot be loaded or is corrupted\n",
        "        return np.zeros((1, len(input_columns)))\n",
        "\n",
        "    # Initialize feature dictionary to store calculated values\n",
        "    features = {}\n",
        "\n",
        "    # --- Spectral features (meanfreq, sd, median, Q25, Q75, IQR, sp.ent, sfm, mode, skew, kurt) ---\n",
        "    # Compute short-time Fourier transform (STFT)\n",
        "    n_fft = 2048 # Standard FFT window size\n",
        "    hop_length = 512 # Standard hop length\n",
        "    D = librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length)\n",
        "    S_magnitude = np.abs(D)\n",
        "\n",
        "    # Calculate power spectrum (magnitude squared) for spectral moments\n",
        "    S_power = S_magnitude**2\n",
        "\n",
        "    # Average power spectrum over time frames to get a single spectral profile\n",
        "    S_avg_power = np.mean(S_power, axis=1)\n",
        "\n",
        "    # Frequencies associated with the STFT bins (in Hz)\n",
        "    freqs_hz = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
        "\n",
        "    # The dataset's 'kHz' values for meanfreq, sd, median, Q25, Q75, IQR, mode are much smaller\n",
        "    # than raw kHz from librosa (max ~11 kHz). This implies a scaling factor was applied.\n",
        "    # Max 'meanfreq' in dataset is ~0.25 kHz. Max possible librosa freq in kHz is sr/2/1000 = 11.025.\n",
        "    # So, apply a global scaling factor to bring librosa's frequencies into the dataset's 'kHz' scale.\n",
        "    # Derived factor: dataset_max_meanfreq / librosa_max_freq_khz (approx 0.25 / 11.025 = 0.0226)\n",
        "    global_freq_scaling_factor = 0.02277 # Based on 0.251124 (dataset max) / (22050/2/1000)\n",
        "\n",
        "    # Apply this scaling to freqs_hz before converting to the dataset's 'kHz'\n",
        "    freqs_khz_scaled = (freqs_hz / 1000.0) * global_freq_scaling_factor\n",
        "\n",
        "    # Ensure S_avg_power is not all zeros before normalization to avoid division by zero\n",
        "    sum_S_avg_power = np.sum(S_avg_power)\n",
        "    if sum_S_avg_power == 0:\n",
        "        # Handle cases with no audible signal (assign defaults)\n",
        "        S_prob = np.zeros_like(S_avg_power)\n",
        "    else:\n",
        "        S_prob = S_avg_power / sum_S_avg_power # Normalize to represent a probability distribution\n",
        "\n",
        "    # Only consider positive normalized frequencies (and their corresponding probability)\n",
        "    positive_freq_indices = freqs_khz_scaled > 0\n",
        "    freqs_pos_khz_scaled = freqs_khz_scaled[positive_freq_indices]\n",
        "    S_prob_pos = S_prob[positive_freq_indices]\n",
        "\n",
        "    if np.sum(S_prob_pos) == 0 or len(freqs_pos_khz_scaled) == 0:\n",
        "        # If no energy in positive frequencies or no positive frequencies, assign defaults\n",
        "        features['meanfreq'] = 0.0\n",
        "        features['sd'] = 0.0\n",
        "        features['median'] = 0.0\n",
        "        features['Q25'] = 0.0\n",
        "        features['Q75'] = 0.0\n",
        "        features['IQR'] = 0.0\n",
        "        features['skew'] = 0.0\n",
        "        features['kurt'] = 0.0\n",
        "        features['mode'] = 0.0\n",
        "    else:\n",
        "        # Mean frequency (in dataset's 'kHz')\n",
        "        features['meanfreq'] = np.sum(freqs_pos_khz_scaled * S_prob_pos)\n",
        "\n",
        "        # Standard deviation of frequency (in dataset's 'kHz')\n",
        "        features['sd'] = np.sqrt(np.sum((freqs_pos_khz_scaled - features['meanfreq'])**2 * S_prob_pos))\n",
        "\n",
        "        # Quantiles (Q25, median, Q75) and IQR from the cumulative distribution\n",
        "        cumulative_S_prob_pos = np.cumsum(S_prob_pos)\n",
        "\n",
        "        # Ensure we don't access out of bounds for quantiles\n",
        "        features['Q25'] = freqs_pos_khz_scaled[np.where(cumulative_S_prob_pos >= 0.25)[0][0]] if len(np.where(cumulative_S_prob_pos >= 0.25)[0]) > 0 else 0.0\n",
        "        features['median'] = freqs_pos_khz_scaled[np.where(cumulative_S_prob_pos >= 0.5)[0][0]] if len(np.where(cumulative_S_prob_pos >= 0.5)[0]) > 0 else 0.0\n",
        "        features['Q75'] = freqs_pos_khz_scaled[np.where(cumulative_S_prob_pos >= 0.75)[0][0]] if len(np.where(cumulative_S_prob_pos >= 0.75)[0]) > 0 else 0.0\n",
        "        features['IQR'] = features['Q75'] - features['Q25']\n",
        "\n",
        "        # Skewness and Kurtosis of the power spectrum distribution (weighted by probability)\n",
        "        mean_freq_val = features['meanfreq']\n",
        "        variance = np.sum((freqs_pos_khz_scaled - mean_freq_val)**2 * S_prob_pos)\n",
        "        std_dev = np.sqrt(variance)\n",
        "\n",
        "        if std_dev > 1e-9:\n",
        "            m3 = np.sum((freqs_pos_khz_scaled - mean_freq_val)**3 * S_prob_pos)\n",
        "            features['skew'] = m3 / (std_dev**3)\n",
        "\n",
        "            m4 = np.sum((freqs_pos_khz_scaled - mean_freq_val)**4 * S_prob_pos)\n",
        "            features['kurt'] = (m4 / (std_dev**4)) - 3 # Excess kurtosis\n",
        "        else:\n",
        "            features['skew'] = 0.0\n",
        "            features['kurt'] = 0.0\n",
        "\n",
        "        # Mode: frequency (in dataset's 'kHz') with the highest magnitude\n",
        "        features['mode'] = freqs_pos_khz_scaled[np.argmax(S_prob_pos)]\n",
        "\n",
        "    # Spectral Entropy (sp.ent) - unitless ratio\n",
        "    eps = 1e-10 # Small epsilon to avoid log(0)\n",
        "    spectral_entropy_val = -np.sum(S_prob * np.log2(S_prob + eps)) # Use S_prob for full spectrum\n",
        "    max_entropy = np.log2(len(S_prob)) if len(S_prob) > 1 else 0\n",
        "    features['sp.ent'] = spectral_entropy_val / max_entropy if max_entropy > 0 else 0.0\n",
        "\n",
        "    # Spectral Flatness Measure (sfm) - unitless ratio\n",
        "    sfm_frames = librosa.feature.spectral_flatness(S=S_magnitude, hop_length=hop_length, power=1) # power=1 for magnitude\n",
        "    features['sfm'] = np.mean(sfm_frames) if sfm_frames.size > 0 else 0.0\n",
        "\n",
        "\n",
        "    # --- Fundamental frequency (F0) related features (meanfun, minfun, maxfun, modindx) --- #\n",
        "    # Using pYIN for pitch detection (robust F0 estimation)\n",
        "    f0, voiced_flag, voiced_probs = librosa.pyin(y=y, sr=sr, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'),\n",
        "                                                 frame_length=n_fft, hop_length=hop_length)\n",
        "    voiced_f0 = f0[voiced_flag]\n",
        "\n",
        "    if len(voiced_f0) == 0:\n",
        "        features['meanfun'] = 0.0\n",
        "        features['minfun'] = 0.0\n",
        "        features['maxfun'] = 0.0\n",
        "        features['modindx'] = 0.0\n",
        "    else:\n",
        "        # Normalizing F0 to match the typical range of 'meanfun' [0.05, 0.25] from dataset\n",
        "        # Max 'meanfun' in dataset is ~0.237. Max human F0 can be ~500Hz. 500 / 2100 = 0.238\n",
        "        f0_normalization_factor_fun = 2100.0\n",
        "        voiced_f0_norm_fun = voiced_f0 / f0_normalization_factor_fun\n",
        "\n",
        "        features['meanfun'] = np.mean(voiced_f0_norm_fun)\n",
        "        features['minfun'] = np.min(voiced_f0_norm_fun)\n",
        "        features['maxfun'] = np.max(voiced_f0_norm_fun)\n",
        "\n",
        "        if len(voiced_f0_norm_fun) > 1:\n",
        "            features['modindx'] = np.std(voiced_f0_norm_fun)\n",
        "        else:\n",
        "            features['modindx'] = 0.0\n",
        "\n",
        "\n",
        "    # --- Dominant frequency features (meandom, mindom, maxdom) --- #\n",
        "    # These are statistics of the spectral peak frequency across frames. (not F0 related here)\n",
        "    dominant_frequencies_per_frame_khz_raw = [] # Store raw kHz from STFT\n",
        "    # Iterate through each frame of the magnitude spectrogram to find the dominant frequency\n",
        "    for t in range(S_magnitude.shape[1]):\n",
        "        frame_power = S_magnitude[:, t]**2\n",
        "        if np.sum(frame_power) > 0:\n",
        "            dominant_idx = np.argmax(frame_power)\n",
        "            # Use the *original* freqs_khz here, then apply the global scaling\n",
        "            dominant_frequencies_per_frame_khz_raw.append(freqs_hz[dominant_idx] / 1000.0)\n",
        "\n",
        "    dominant_frequencies_per_frame_khz_raw = np.array(dominant_frequencies_per_frame_khz_raw)\n",
        "\n",
        "    if len(dominant_frequencies_per_frame_khz_raw) == 0:\n",
        "        features['meandom'] = 0.0\n",
        "        features['mindom'] = 0.0\n",
        "        features['maxdom'] = 0.0\n",
        "    else:\n",
        "        # Now apply the global scaling factor to these dominant frequencies as well\n",
        "        normalized_dominant_frequencies = dominant_frequencies_per_frame_khz_raw * global_freq_scaling_factor\n",
        "\n",
        "        features['meandom'] = np.mean(normalized_dominant_frequencies)\n",
        "        features['mindom'] = np.min(normalized_dominant_frequencies)\n",
        "        features['maxdom'] = np.max(normalized_dominant_frequencies)\n",
        "\n",
        "    # Handle potential NaN or Inf values by replacing them with 0 after all calculations\n",
        "    for key in features:\n",
        "        if np.isnan(features[key]) or np.isinf(features[key]):\n",
        "            features[key] = 0.0\n",
        "\n",
        "    # Ensure the order of extracted features matches the input_columns list\n",
        "    extracted_features_ordered = [features[col] for col in input_columns]\n",
        "\n",
        "    # Debugging print: Show raw extracted features before scaling/clipping\n",
        "    # print(f\"--- Extracted features for {os.path.basename(file_path)} (before scaling/clipping) ---\")\n",
        "    for i, col_name in enumerate(input_columns):\n",
        "        min_val_train = scaler.data_min_[i]\n",
        "        max_val_train = scaler.data_max_[i]\n",
        "        val = extracted_features_ordered[i]\n",
        "        # print(f\"  {col_name}: {val:.6f} (Train range: [{min_val_train:.6f}, {max_val_train:.6f}])\")\n",
        "    # print(\"------------------------------------------------------\")\n",
        "\n",
        "    # Convert to NumPy array and reshape to (1, -1) for MinMaxScaler\n",
        "    features_array = np.array(extracted_features_ordered).reshape(1, -1)\n",
        "\n",
        "    # --- Clip features to the range of training data before scaling to prevent extrapolation ---\n",
        "    if features_array.shape[1] == scaler.data_min_.shape[0]:\n",
        "        for i, col_name in enumerate(input_columns):\n",
        "            original_val = features_array[0, i]\n",
        "            min_val = scaler.data_min_[i]\n",
        "            max_val = scaler.data_max_[i]\n",
        "\n",
        "            # Apply clipping\n",
        "            features_array[0, i] = np.clip(original_val, min_val, max_val)\n",
        "    else:\n",
        "        print(\"Warning: Feature array shape does not match scaler's input dimension. Clipping skipped.\")\n",
        "\n",
        "    # Apply the pre-fitted MinMaxScaler to transform the features\n",
        "    scaled_features = scaler.transform(features_array)\n",
        "\n",
        "    return scaled_features\n",
        "\n",
        "# print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d161eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d161eb",
        "outputId": "7ddc0d2e-bb62-4538-b6cd-d0c69ae980b0"
      },
      "outputs": [],
      "source": [
        "model.load_weights('gender_recognition_voice.keras')\n",
        "print(\"Loaded model weights from 'gender_recognition_voice.keras'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd4957d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dd4957d",
        "outputId": "1d76a776-2e9b-4309-9c4e-f8cd5b050b93"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Suppress warnings from librosa, etc.\n",
        "\n",
        "# List of user's 'male' recordings to process\n",
        "recorded_audio_files = ['/justin.wav', '/sahiba.wav', '/pretty_little.wav','/vikram.wav']\n",
        "\n",
        "for audio_file_path in recorded_audio_files:\n",
        "    # 1. Extract and scale features from the audio file\n",
        "    scaled_audio_features = extract_features_and_scale(audio_file_path, min_max_scaler, input_columns)\n",
        "\n",
        "    # 2. Use the model to predict the gender from the scaled features\n",
        "    model_prediction = model.predict(scaled_audio_features)[0]\n",
        "\n",
        "    # 3. Determine the predicted gender\n",
        "    pred_index = np.argmax(model_prediction)\n",
        "    predicted_gender = output_columns[pred_index]\n",
        "\n",
        "    # 4. Print the path of the processed audio file, the predicted gender, and the associated probability\n",
        "    print(f\"\\n------------------------------------------------------\")\n",
        "    print(f\"Processing audio file: '{audio_file_path}'\")\n",
        "    print(f\"Predicted gender: {predicted_gender}\")\n",
        "    print(f\"Prediction probabilities (male, female): {model_prediction}\")\n",
        "    print(f\"Prediction probability for {predicted_gender}: {model_prediction[pred_index]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SI2S6o8-EGMY",
      "metadata": {
        "id": "SI2S6o8-EGMY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
